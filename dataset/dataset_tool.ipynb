{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "csv_path = 'H://reddit/corgis/'\n",
    "df = pd.read_csv(os.path.join(csv_path, 'submissions_clean.csv'))\n",
    "img_dir = os.path.join(csv_path, 'img')\n",
    "label_dir = os.path.join(csv_path, 'labels')\n",
    "\n",
    "pathlib.Path(img_dir).mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(label_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "for item in df.iterrows():\n",
    "    item = item[1]\n",
    "    filename = item['id']\n",
    "    if os.path.isfile(os.path.join(csv_path, 'images', filename+'.jpg')):\n",
    "        filename += '.jpg'\n",
    "    elif os.path.isfile(os.path.join(csv_path, 'images', filename+'.jpeg')):\n",
    "        filename += '.jpeg'\n",
    "    elif os.path.isfile(os.path.join(csv_path, 'images', filename+'.png')):\n",
    "        filename += '.png'\n",
    "    else:\n",
    "        print(filename)\n",
    "        \n",
    "    bbox = np.array([[item['bboxX'], item['bboxY'], item['bboxX'] + item['bboxSize'], item['bboxY'] + item['bboxSize']]])\n",
    "    labels = np.array([18])\n",
    "    scores = np.array([1.0])\n",
    "    dick = {'boxes': bbox, 'labels': labels, 'scores': scores}\n",
    "    pickle.dump(dick, open(os.path.join(label_dir, filename.split('.')[0] + '.pkl'), 'wb'))\n",
    "    shutil.copyfile(os.path.join(csv_path, 'images', filename), os.path.join(img_dir, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for picl in os.listdir(pred_dir):\n",
    "    prediction = pickle.load(open(os.path.join(pred_dir, picl), 'rb'))\n",
    "    for key, val in prediction.items():\n",
    "        prediction[key] = val.detach().numpy()\n",
    "    pickle.dump(prediction, open(os.path.join(pred_dir, picl), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Faster RCNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "import pickle\n",
    "import hashlib\n",
    "\n",
    "image_dir = './corgis'\n",
    "pred_dir = os.path.join(image_dir, 'labels')\n",
    "super_dir = os.path.join(image_dir, 'supervision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "# For training\n",
    "images, boxes = torch.rand(4, 3, 600, 1200), torch.rand(4, 11, 4)\n",
    "\n",
    "# For inference\n",
    "model.eval()\n",
    "predictions = model([images[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path(pred_dir).mkdir(parents=True, exist_ok=True)\n",
    "image_names = os.listdir(image_dir)\n",
    "\n",
    "for image_name in tqdm(os.listdir(image_dir)):\n",
    "    if os.path.isdir(os.path.join(image_name, file_name)): continue\n",
    "    image = Image.open(os.path.join(image_dir, image_name))\n",
    "    image_tensor = ToTensor()(image).unsqueeze(0)\n",
    "    model.eval()\n",
    "    predictions = model(image_tensor)[0]\n",
    "    for key, value in predictions.items():\n",
    "        predictions[key] = value.detach().numpy()\n",
    "        \n",
    "    pickle.dump(predictions, open(os.path.join(pred_dir, image_name.split('.')[0] + '.pkl'), \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean (videos, dups, small res)\n",
    "Todo: can not open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_videos(image_dir):\n",
    "    file_names = os.listdir(image_dir)\n",
    "    for file_name in file_names:\n",
    "        if os.path.isdir(os.path.join(image_dir, file_name)):\n",
    "            continue\n",
    "        ext = file_name.split('.')\n",
    "        if len(ext) < 2 or ext[1] not in ['jpg', 'jpeg', 'png']:\n",
    "            os.remove(os.path.join(image_dir, file_name))\n",
    "            \n",
    "remove_videos(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_size_dict(image_dir):\n",
    "    image_names = os.listdir(image_dir)\n",
    "    size_dict = {}\n",
    "    for image_name in tqdm(image_names):\n",
    "        if os.path.isdir(os.path.join(image_dir, image_name)): continue\n",
    "        \n",
    "        image = Image.open(os.path.join(image_dir, image_name))\n",
    "        w,h = image.size\n",
    "        size_str = f'{w}x{h}'\n",
    "        if size_str not in size_dict.keys():\n",
    "            size_dict[size_str] = [image_name]\n",
    "        else:\n",
    "            size_dict[size_str] = size_dict[size_str] + [image_name]\n",
    "            \n",
    "    return size_dict\n",
    "\n",
    "size_dict = create_size_dict(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed = 0\n",
    "remove_keys = []\n",
    "for size in size_dict.keys():\n",
    "    w, h = [int(x) for x in size.split('x')]\n",
    "    if w < 700 and h < 700:\n",
    "        for image_name in size_dict[size]:\n",
    "            os.remove(os.path.join(image_dir, image_name))\n",
    "            removed += 1\n",
    "        remove_keys.append(size)\n",
    "        \n",
    "for key in remove_keys:\n",
    "    size_dict.pop(key, None)\n",
    "\n",
    "print(removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed = 0\n",
    "for size in size_dict.keys():\n",
    "    if len(size_dict[size]) < 2:\n",
    "        continue\n",
    "    \n",
    "    hashes = []\n",
    "    image_files = []\n",
    "    for image_file in size_dict[size]:\n",
    "        hash_md5 = hashlib.md5()\n",
    "        with open(os.path.join(image_dir, image_file), \"rb\") as f:\n",
    "            for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "                hash_md5.update(chunk)\n",
    "        hashes.append(hash_md5.hexdigest())\n",
    "        image_files.append(image_file)\n",
    "        \n",
    "    unique_hashes = set(hashes)\n",
    "    for h in unique_hashes:\n",
    "        cnt = hashes.count(h)\n",
    "        if cnt > 1:\n",
    "            idxs = [i for i in range(len(hashes)) if hashes[i] == h]\n",
    "            idxs.pop(0)\n",
    "            for idx in idxs:\n",
    "                os.remove(os.path.join(image_dir, image_files[idx]))\n",
    "                removed +=1\n",
    "\n",
    "print(removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter bassed on bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# https://stackoverflow.com/questions/25349178/calculating-percentage-of-bounding-box-overlap-for-image-detector-evaluation/42874377\n",
    "def get_overlap(bb1, bb2):\n",
    "    x_left = max(bb1[0], bb2[0])\n",
    "    y_top = max(bb1[1], bb2[1])\n",
    "    x_right = min(bb1[2], bb2[2])\n",
    "    y_bottom = min(bb1[3], bb2[3])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    bb1_area = (bb1[2] - bb1[0]) * (bb1[3] - bb1[1])\n",
    "    bb2_area = (bb2[2] - bb2[0]) * (bb2[3] - bb2[1])\n",
    "\n",
    "    overlap1 = intersection_area/bb1_area\n",
    "    overlap2 = intersection_area/bb2_area\n",
    "    return overlap1, overlap2\n",
    "\n",
    "image_names = os.listdir(image_dir)\n",
    "pathlib.Path(super_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for image_name in tqdm(os.listdir(image_dir)):\n",
    "    if os.path.isdir(os.path.join(image_dir, image_name)): continue\n",
    "        \n",
    "    basename, ext = image_name.split('.')\n",
    "    \n",
    "    prediction = pickle.load(open(os.path.join(pred_dir, basename+'.pkl'), 'rb'))\n",
    "    print(prediction)\n",
    "    break\n",
    "    #print(prediction)\n",
    "\n",
    "    #print(image_name)\n",
    "    \n",
    "    im = Image.open(os.path.join(image_dir, image_name))\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    dog_idxs = np.argwhere((prediction['labels'] == 18) & (prediction['scores'] > 0.9)).flatten()\n",
    "    dog_bboxes = prediction['boxes']\n",
    "    \n",
    "    dog_idxs_nms = []\n",
    "    if True:\n",
    "        overlap_thresh = 0.7\n",
    "        area = lambda bbox: (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "        for i, idx1 in enumerate(dog_idxs):\n",
    "            delete = False\n",
    "            for j, idx2 in enumerate(dog_idxs):\n",
    "                if i == j: continue\n",
    "\n",
    "                # Check IOU\n",
    "                bbox1 = dog_bboxes[idx1]\n",
    "                bbox2 = dog_bboxes[idx2]\n",
    "                overlap1, overlap2 = get_overlap(bbox1, bbox2)\n",
    "\n",
    "                # If overlap and current bbox is smaller than box compared to, then discard this bbox\n",
    "                if overlap1 > overlap2 and overlap1 > overlap_thresh:\n",
    "                    delete = True\n",
    "                    break\n",
    "            if not delete: dog_idxs_nms.append(idx1)\n",
    "    else:\n",
    "        dog_idxs_nms = dog_idxs\n",
    "        \n",
    "    if len(dog_idxs_nms) != 1:\n",
    "        os.rename(os.path.join(image_dir, image_name), os.path.join(super_dir, image_name))\n",
    "    \n",
    "    #for d in dog_idxs_nms:\n",
    "    #    draw.rectangle(prediction['boxes'].detach().numpy()[d])\n",
    "        \n",
    "    #display(im)\n",
    "    \n",
    "    #print(dog_mask)\n",
    "    #i += 1\n",
    "    #if i == 30: break\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = os.listdir(image_dir)\n",
    "crop_dir = os.path.join(image_dir, 'crop')\n",
    "pathlib.Path(crop_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "k = 0\n",
    "for image_name in tqdm(os.listdir(image_dir)):\n",
    "    if os.path.isdir(os.path.join(image_dir, image_name)): continue\n",
    "    basename, ext = image_name.split('.')\n",
    "    \n",
    "    prediction = pickle.load(open(os.path.join(pred_dir, basename+'.pkl'), 'rb'))\n",
    "    im = Image.open(os.path.join(image_dir, image_name)).convert('RGB')\n",
    "    dog_idxs = np.argwhere((prediction['labels'] == 18) & (prediction['scores'] > 0.7)).flatten()\n",
    "    dog_bboxes = prediction['boxes']\n",
    "    \n",
    "    dog_idxs_nms = []\n",
    "    if True:\n",
    "        overlap_thresh = 0.7\n",
    "        area = lambda bbox: (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "        for i, idx1 in enumerate(dog_idxs):\n",
    "            delete = False\n",
    "            for j, idx2 in enumerate(dog_idxs):\n",
    "                if i == j: continue\n",
    "\n",
    "                # Check IOU\n",
    "                bbox1 = dog_bboxes[idx1]\n",
    "                bbox2 = dog_bboxes[idx2]\n",
    "                overlap1, overlap2 = get_overlap(bbox1, bbox2)\n",
    "\n",
    "                # If overlap and current bbox is smaller than box compared to, then discard this bbox\n",
    "                if overlap1 > overlap2 and overlap1 > overlap_thresh:\n",
    "                    delete = True\n",
    "                    break\n",
    "            if not delete: dog_idxs_nms.append(idx1)\n",
    "    else:\n",
    "        dog_idxs_nms = dog_idxs\n",
    "        \n",
    "    idx = dog_idxs_nms[0]\n",
    "    bbox = dog_bboxes[idx]\n",
    "    w, h = im.size\n",
    "    min_side_img = min(w, h)\n",
    "    \n",
    "    # Scale to at least 1024 pixels\n",
    "    scale_f = 1.0\n",
    "    if min_side_img < 1024:\n",
    "        scale_f = 1024/min_side_img\n",
    "        im = im.resize((int(w*scale_f), int(h*scale_f)))\n",
    "        w, h = im.size\n",
    "    \n",
    "    bbox *= scale_f\n",
    "    min_side_img = min(w, h)\n",
    "    \n",
    "    max_side_bbox = int(max(bbox[2] - bbox[0], bbox[3] - bbox[1]))\n",
    "\n",
    "    # Ensure that crop is at least 1024, fits into image and, if possible, has size max_side_bbox + max_size_img/10\n",
    "    crop_size = min(min_side_img, max(1024, max_side_bbox + min_side_img/10))\n",
    "\n",
    "    bbox_center_x = bbox[0] + (bbox[2]-bbox[0])/2\n",
    "    bbox_center_y = bbox[1] + (bbox[3]-bbox[1])/2\n",
    "    crop_x = max(0, bbox_center_x-crop_size/2)\n",
    "    crop_y = max(0, bbox_center_y-crop_size/2)\n",
    "    crop_x_over = w - (crop_x + crop_size)\n",
    "    crop_y_over = h - (crop_y + crop_size)\n",
    "    if crop_x_over < 0:\n",
    "        crop_x += crop_x_over\n",
    "    if crop_y_over < 0:\n",
    "        crop_y += crop_y_over\n",
    "        \n",
    "    #draw = ImageDraw.Draw(im)\n",
    "    #draw.point([bbox_center_x, bbox_center_y], fill='red')\n",
    "    #draw.rectangle(bbox, outline='blue')\n",
    "    #draw.rectangle((crop_x, crop_y, crop_x + crop_size, crop_y + crop_size), outline='red')\n",
    "    #display(im)\n",
    "    #display(im)\n",
    "    #display(im.crop(crop_x, crop_y, crop_x + crop_size, crop_y + crop_size))\n",
    "    im_crop = im.crop((crop_x, crop_y, crop_x + crop_size, crop_y + crop_size))\n",
    "    im_crop.save(os.path.join(crop_dir, image_name), \"JPEG\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagededup.methods import PHash\n",
    "phasher = PHash()\n",
    "\n",
    "# Generate encodings for all images in an image directory\n",
    "encodings = phasher.encode_images(image_dir='corgis')\n",
    "\n",
    "# Find duplicates using the generated encodings\n",
    "duplicates = phasher.find_duplicates(encoding_map=encodings)\n",
    "\n",
    "# plot duplicates obtained for a given file using the duplicates dictionary\n",
    "from imagededup.utils import plot_duplicates\n",
    "plot_duplicates(image_dir='corgis',\n",
    "                duplicate_map=duplicates,\n",
    "                filename='ukbench00120.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_duplicates(image_dir='corgis',\n",
    "                duplicate_map=duplicates,\n",
    "                filename='100082095_112963816898945_1812614927344669390_n.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = input()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_keys = [key for key in duplicates.keys() if len(duplicates[key]) != 0]\n",
    "print(len(duplicate_keys))\n",
    "to_be_deleted = []\n",
    "for key in duplicates.keys():\n",
    "    if key in duplicate_keys:\n",
    "        plot_duplicates(image_dir='corgis',\n",
    "                duplicate_map=duplicates,\n",
    "                filename=key)\n",
    "        \n",
    "        delete = input('Press x if duplicates should be deleted')\n",
    "        if delete == 'x':\n",
    "            to_be_deleted.extend(duplicates[key])\n",
    "            for dup in duplicates[key]:\n",
    "                duplicate_keys.remove(dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_keys = [key for key in duplicates.keys() if len(duplicates[key]) != 0]\n",
    "#removed = 0\n",
    "for key in duplicates.keys():\n",
    "    if key in duplicate_keys:\n",
    "        for dup in duplicates[key]:\n",
    "            try:\n",
    "                os.remove(os.path.join(image_dir, dup))\n",
    "                duplicate_keys.remove(dup)\n",
    "            except:\n",
    "                print('ohoh')\n",
    "                pass\n",
    "            removed += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████▋                                                                     | 4/30 [23:42<2:20:51, 325.07s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "profiles = ['genthecorgi','corgi_shumai','corgi_foxy','corgi.mob','corgi_nola','currydecorgi','lecorgi','thesportycorgi','iggy_corgi','corgiofigs','pino.the.corgi','corgiexotic','sake_thecorgi','myfavcorgi','ralphthecorgi','topithecorgi','corgithings','the_corgi_yoshi','tofu_corgi','jamie_the_dutch_corgi','corgisonstairs','corgi.kevin','corgi.persey','mac_corgi','poncho.the.corgi','mabelthetricorgi','corgimowgli','lychee_the_corgi','corgisftw','bootsythecorgi']\n",
    "#'lacorgi', 'madmax_fluffyroad','corgiarya','corgis.hub',\n",
    "for profile in tqdm(profiles):\n",
    "    os.system(f'instaloader --no-videos --no-video-thumbnails --no-captions --no-metadata-json --no-profile-pic {profile}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
